# coding:utf-8
# database_manager.py
"""
æ•°æ®åº“ç®¡ç†æ¨¡å—
ç”¨äºå°†å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æ•°æ®å®æ—¶æ’å…¥åˆ°MySQLæ•°æ®åº“ä¸­
"""

import pymysql
import logging
import random
import string
import os
from datetime import datetime
from typing import Dict, List, Optional, Any
import time

from src.database.database_config import get_table_config

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨ï¼Œè´Ÿè´£å¾®ä¿¡å…¬ä¼—å·æ–‡ç« æ•°æ®çš„æ•°æ®åº“æ“ä½œ

    2025-08 å˜æ›´è¯´æ˜ï¼š
    æŒ‰éœ€æ±‚æš‚æ—¶åœæ­¢ä¿å­˜ gzh_name å­—æ®µï¼ˆæ•°æ®åº“å·²åˆ é™¤è¯¥åˆ—ï¼‰ã€‚
    ä¸ºæœ€å°æ”¹åŠ¨ï¼Œä»…åœ¨æ’å…¥é€»è¾‘ä¸­ç§»é™¤ gzh_nameï¼Œç›¸å…³è§£æ/å›å¡«æ–¹æ³•ä¿ç•™ä½†ä¸å†ä½¿ç”¨ã€‚
    è‹¥éœ€æ¢å¤ï¼Œåªéœ€æ¢å¤ insert SQL ä¸­åˆ—åŠå¯¹åº” insert_data ç»„è£…ã€‚"""
    
    def __init__(self, host='127.0.0.1', port=3306, user='root', password='root', database='faxuan', table_name: Optional[str] = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        
        Args:
            host: æ•°æ®åº“ä¸»æœºåœ°å€
            port: æ•°æ®åº“ç«¯å£
            user: æ•°æ®åº“ç”¨æˆ·å
            password: æ•°æ®åº“å¯†ç 
            database: æ•°æ®åº“åç§°
        """
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.database = database
        self.connection = None
        self.logger = logging.getLogger(__name__)

        # è¯»å–è¡¨é…ç½®
        table_cfg = get_table_config()
        self.table_name = table_name or table_cfg.get('table_name', 'fx_article_records')
        self.crawl_channel_default = table_cfg.get('crawl_channel_default', 'å¾®ä¿¡å…¬ä¼—å·')

        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        self.connect()
    
    def connect(self) -> bool:
        """å»ºç«‹æ•°æ®åº“è¿æ¥"""
        try:
            self.connection = pymysql.connect(
                host=self.host,
                port=self.port,
                user=self.user,
                password=self.password,
                database=self.database,
                charset='utf8mb4',
                autocommit=True,  # è‡ªåŠ¨æäº¤
                cursorclass=pymysql.cursors.DictCursor
            )
            self.logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ: {self.host}:{self.port}/{self.database}")
            return True
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection:
            self.connection.close()
            self.logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def is_connected(self) -> bool:
        """æ£€æŸ¥æ•°æ®åº“è¿æ¥çŠ¶æ€"""
        try:
            if self.connection:
                self.connection.ping(reconnect=True)
                return True
        except:
            return False
        return False
    
    def reconnect(self) -> bool:
        """é‡æ–°è¿æ¥æ•°æ®åº“"""
        self.logger.info("å°è¯•é‡æ–°è¿æ¥æ•°æ®åº“...")
        self.disconnect()
        return self.connect()
    
    def generate_article_id(self, crawl_time: datetime) -> str:
        """
        ç”Ÿæˆæ–‡ç« ID
        æ ¼å¼ï¼šå‰12ä½ä¸ºcrawl_timeæ—¶é—´(YYYYMMDDHHMM)ï¼Œå4ä½ä¸ºéšæœºæ•°
        
        Args:
            crawl_time: çˆ¬å–æ—¶é—´
            
        Returns:
            ç”Ÿæˆçš„æ–‡ç« ID
        """
        # å‰12ä½ï¼šå¹´æœˆæ—¥æ—¶åˆ†
        time_part = crawl_time.strftime('%Y%m%d%H%M')
        
        # å4ä½ï¼šéšæœºæ•°
        random_part = ''.join(random.choices(string.digits, k=4))
        
        return time_part + random_part
    
    def insert_article(self, article_data: Dict[str, Any]) -> bool:
        """
        æ’å…¥å•ç¯‡æ–‡ç« æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            article_data: æ–‡ç« æ•°æ®å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - title: æ–‡ç« æ ‡é¢˜ (å¿…å¡«)
                - content: æ–‡ç« å†…å®¹ (å¯é€‰)
                - url: æ–‡ç« é“¾æ¥ (å¯é€‰)
                - pub_time: å‘å¸ƒæ—¶é—´ (å¯é€‰)
                - crawl_time: çˆ¬å–æ—¶é—´ (å¿…å¡«)
                - unit_name: å•ä½åç§°ï¼ˆåŸä» gzh_name è§£æï¼Œç°ç›´æ¥ä¼ å…¥ï¼‰
                - view_count: é˜…è¯»é‡ (å¯é€‰)
                - like_count: ç‚¹èµæ•° (å¯é€‰) -> æ˜ å°„åˆ°æ•°æ®åº“çš„ likes å­—æ®µ
                - share_count: åˆ†äº«æ•° (å¯é€‰) -> æ˜ å°„åˆ°æ•°æ®åº“çš„ comments å­—æ®µ
                
        Returns:
            æ’å…¥æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        if not self.is_connected():
            if not self.reconnect():
                return False

        # å…è®¸å¤–éƒ¨å®ç° upsertï¼›æ­¤å¤„ä¸å†ä¸»åŠ¨å»é‡ï¼Œè°ƒç”¨è€…å¯å…ˆæ£€æŸ¥æˆ–ç›´æ¥ä½¿ç”¨ upsert_article
        # article_title = (article_data.get('title') or '').strip()

        try:
            # å‡†å¤‡æ•°æ®
            current_time = datetime.now()
            crawl_time = article_data.get('crawl_time')
            
            # å¦‚æœcrawl_timeæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºdatetimeå¯¹è±¡
            if isinstance(crawl_time, str):
                try:
                    crawl_time = datetime.strptime(crawl_time, '%Y-%m-%d %H:%M:%S')
                except ValueError:
                    crawl_time = current_time
            elif not isinstance(crawl_time, datetime):
                crawl_time = current_time
            
            # å¤„ç†å‘å¸ƒæ—¶é—´
            publish_time = article_data.get('pub_time')
            if isinstance(publish_time, str):
                try:
                    publish_time = datetime.strptime(publish_time, '%Y-%m-%d %H:%M:%S')
                except ValueError:
                    publish_time = None
            elif not isinstance(publish_time, datetime):
                publish_time = None
            
            # ç”Ÿæˆæ–‡ç« ID
            article_id = self.generate_article_id(crawl_time)
            
            # è§£æ unit_nameï¼šä¼˜å…ˆç”¨ä¼ å…¥ unit_nameï¼›å¦åˆ™ç”¨ gzh_name å»å¯¹ç…§è¡¨æŸ¥ï¼›æŸ¥ä¸åˆ°åˆ™ç•™ç©ºï¼ˆä¸å†ç›´æ¥ç”¨å…¬ä¼—å·åç§°é¡¶æ›¿ï¼‰
            unit_name = (article_data.get('unit_name') or '').strip()
            if (not unit_name) and article_data.get('gzh_name'):
                resolved = self.resolve_unit_name(article_data.get('gzh_name'))
                if resolved:
                    unit_name = resolved
                else:
                    self.logger.debug(f"æœªåœ¨å¯¹ç…§è¡¨ä¸­æ‰¾åˆ°å…¬ä¼—å· '{article_data.get('gzh_name')}' å¯¹åº”å•ä½ï¼Œunit_name ç•™ç©ºä»¥ä¾¿åç»­è¡¥é½")

            # è®¡ç®— analysis å­—æ®µçš„å€¼
            # å½“é˜…è¯»é‡ä¸º0ä¸”å…¶ä½™ç‚¹èµé‡æˆ–è€…å–œæ¬¢é‡æœ‰ä¸€ä¸ªä¸ä¸º0æ—¶è®¾ä¸º-1ï¼Œå…¶ä»–æ—¶å€™å‡è®¾ä¸º0
            view_count = article_data.get('view_count') or 0
            likes = article_data.get('like_count') or 0
            thumbs_count = article_data.get('old_like_count') or 0
            
            # è½¬æ¢ä¸ºæ•°å­—è¿›è¡Œæ¯”è¾ƒ
            try:
                view_count = int(view_count) if view_count else 0
                likes = int(likes) if likes else 0
                thumbs_count = int(str(thumbs_count).replace(',', '')) if thumbs_count else 0
            except (ValueError, TypeError):
                view_count = 0
                likes = 0
                thumbs_count = 0
            
            # åˆ¤æ–­åˆ†æå€¼ï¼šå½“é˜…è¯»é‡ä¸º0ä¸”ç‚¹èµé‡æˆ–å–œæ¬¢é‡æœ‰ä¸€ä¸ªä¸ä¸º0æ—¶è®¾ä¸º-1ï¼Œå¦åˆ™è®¾ä¸º0
            if view_count == 0 and (likes > 0 or thumbs_count > 0):
                analysis_value = -1
            else:
                analysis_value = 0

            # å‡†å¤‡æ’å…¥æ•°æ®
            insert_data = {
                'crawl_time': crawl_time,
                'crawl_channel': self.crawl_channel_default,
                # gzh_name å­—æ®µå·²ç§»é™¤
                'unit_name': unit_name,
                'article_title': article_data.get('title', ''),
                'article_content': article_data.get('content', ''),
                'publish_time': publish_time,
                'view_count': article_data.get('view_count'),
                'likes': article_data.get('like_count'),                 # å–œæ¬¢é‡
                'share_count': article_data.get('share_count'),           # åˆ†äº«é‡
                'thumbs_count': article_data.get('old_like_count'),       # ç‚¹èµé‡(å†å²ç‚¹èµ)
                'comments': article_data.get('comment_count'),            # è¯„è®ºé‡
                'article_url': article_data.get('url', ''),
                'article_id': article_id,
                'create_time': current_time,
                'update_time': current_time,
                'analysis': analysis_value                                # åˆ†æå­—æ®µ
            }

            # å·²ç§»é™¤åŸºäº gzh_name çš„å¯¹ç…§è§£æé€»è¾‘ï¼›è‹¥éœ€æ¢å¤è¯·è°ƒç”¨ resolve_unit_name()
            
            # æ„å»ºSQLè¯­å¥
            sql = f"""
            /* gzh_name å·²åˆ é™¤ï¼Œæ’å…¥åˆ—åŒæ­¥è°ƒæ•´ */
            INSERT INTO {self.table_name}
            (crawl_time, crawl_channel, unit_name, article_title, article_content,
             publish_time, view_count, likes, share_count, thumbs_count, comments, article_url, article_id, create_time, update_time, analysis)
            VALUES
            (%(crawl_time)s, %(crawl_channel)s, %(unit_name)s, %(article_title)s, %(article_content)s,
             %(publish_time)s, %(view_count)s, %(likes)s, %(share_count)s, %(thumbs_count)s, %(comments)s, %(article_url)s, %(article_id)s, %(create_time)s, %(update_time)s, %(analysis)s)
            """
            
            # æ‰§è¡Œæ’å…¥
            with self.connection.cursor() as cursor:
                cursor.execute(sql, insert_data)
            
            self.logger.info(f"âœ… æ–‡ç« æ’å…¥æˆåŠŸ: {article_data.get('title', 'Unknown')} (ID: {article_id})")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ–‡ç« æ’å…¥å¤±è´¥: {e}")
            self.logger.error(f"æ–‡ç« æ•°æ®: {article_data}")
            return False
    
    def batch_insert_articles(self, articles_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """
        æ‰¹é‡æ’å…¥æ–‡ç« æ•°æ®

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨

        Returns:
            åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸: {'success': æˆåŠŸæ•°é‡, 'duplicate': é‡å¤æ•°é‡, 'failed': å¤±è´¥æ•°é‡}
        """
        if not articles_data:
            self.logger.warning("æ²¡æœ‰æ–‡ç« æ•°æ®éœ€è¦æ’å…¥")
            return {'success': 0, 'duplicate': 0, 'failed': 0}

        success_count = 0
        duplicate_count = 0
        failed_count = 0
        total_count = len(articles_data)

        self.logger.info(f"å¼€å§‹æ‰¹é‡æ’å…¥ {total_count} ç¯‡æ–‡ç« ...")

        for i, article_data in enumerate(articles_data, 1):
            try:
                article_title = article_data.get('title', 'Unknown')

                # æŒ‰æ ‡é¢˜å»é‡
                if (article_data.get('title', '').strip() and 
                    self.check_article_title_exists(article_data.get('title', '').strip())):
                    duplicate_count += 1
                    self.logger.info(f"è¿›åº¦: {i}/{total_count} - æ ‡é¢˜é‡å¤ï¼Œè·³è¿‡: {article_title}")
                    continue

                if self.insert_article(article_data):
                    success_count += 1
                    self.logger.info(f"è¿›åº¦: {i}/{total_count} - æˆåŠŸæ’å…¥æ–‡ç« : {article_title}")
                else:
                    failed_count += 1
                    self.logger.error(f"è¿›åº¦: {i}/{total_count} - æ’å…¥å¤±è´¥: {article_title}")

                # æ·»åŠ å°å»¶è¿Ÿé¿å…æ•°æ®åº“å‹åŠ›è¿‡å¤§
                time.sleep(0.1)

            except Exception as e:
                failed_count += 1
                self.logger.error(f"æ‰¹é‡æ’å…¥ç¬¬ {i} ç¯‡æ–‡ç« æ—¶å‡ºé”™: {e}")

        result = {'success': success_count, 'duplicate': duplicate_count, 'failed': failed_count}
        self.logger.info(f"æ‰¹é‡æ’å…¥å®Œæˆ: æˆåŠŸ {success_count} ç¯‡ï¼Œé‡å¤ {duplicate_count} ç¯‡ï¼Œå¤±è´¥ {failed_count} ç¯‡")
        return result

    def backfill_unit_name_from_contrast(self, contrast_table: str = 'fx_unit_gzh_contrast') -> int:
        """
        ä½¿ç”¨å¯¹ç…§è¡¨æ ¹æ® gzh_name å›å¡«/æ›´æ–° unit_nameã€‚

        ä»…æ›´æ–°å½“å‰è¡¨ä¸­ unit_name ä¸ºç©ºæˆ–ç©ºä¸²çš„è®°å½•ã€‚

        Args:
            contrast_table: å¯¹ç…§è¡¨è¡¨åï¼Œé»˜è®¤ 'fx_unit_gzh_contrast'

        Returns:
            å—å½±å“çš„è¡Œæ•°ï¼ˆä¼°è®¡å€¼ï¼Œå— autocommit/é©±åŠ¨å®ç°å½±å“ï¼‰
        """
        if not self.is_connected():
            if not self.reconnect():
                return 0

        try:
            sql = f"""
            UPDATE {self.table_name} ar
            LEFT JOIN {contrast_table} c ON ar.gzh_name = c.gzh_name
            SET ar.unit_name = COALESCE(c.unit_name, ar.unit_name)
            WHERE (ar.unit_name IS NULL OR ar.unit_name = '') AND c.unit_name IS NOT NULL
            """
            with self.connection.cursor() as cursor:
                affected = cursor.execute(sql)
            self.logger.info(f"âœ… å•ä½åç§°å›å¡«å®Œæˆï¼Œå—å½±å“è¡Œæ•°: {affected}")
            return affected or 0
        except Exception as e:
            self.logger.error(f"âŒ å›å¡«å•ä½åç§°å¤±è´¥: {e}")
            return 0
    
    def check_article_exists(self, article_url: str) -> bool:
        """
        æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ ¹æ®URLåˆ¤æ–­ï¼‰

        Args:
            article_url: æ–‡ç« URL

        Returns:
            å­˜åœ¨è¿”å›Trueï¼Œä¸å­˜åœ¨è¿”å›False
        """
        if not self.is_connected():
            if not self.reconnect():
                return False

        try:
            sql = f"SELECT COUNT(*) as count FROM {self.table_name} WHERE article_url = %s"
            with self.connection.cursor() as cursor:
                cursor.execute(sql, (article_url,))
                result = cursor.fetchone()
                return result['count'] > 0
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥æ–‡ç« æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: {e}")
            return False

    # ===================== æ–°å¢ï¼šæ›´æ–° & Upsert æ”¯æŒ =====================
    def update_article_stats(self, article_title: str, article_data: Dict[str, Any]) -> bool:
        """æ ¹æ®æ–‡ç« æ ‡é¢˜æ›´æ–°ç»Ÿè®¡æ•°æ® / å†…å®¹ç­‰å­—æ®µï¼ˆè‹¥å­˜åœ¨ï¼‰ã€‚

        è¯´æ˜ï¼š
            - ä»¥ article_title ä½œä¸ºåŒ¹é…æ¡ä»¶ï¼ˆç°æœ‰è¡¨ä»¥æ ‡é¢˜è¿‘ä¼¼å”¯ä¸€ï¼Œæ²¿ç”¨æ—¢æœ‰é€»è¾‘ï¼‰ã€‚
            - æ›´æ–°å­—æ®µï¼šview_count, likes, commentsï¼ˆé˜…è¯»/ç‚¹èµ/è¯„è®ºï¼‰ï¼Œä»¥åŠ article_contentï¼ˆå¯è¦†ç›–ï¼‰
              article_urlï¼ˆè‹¥ä¼ å…¥éç©ºï¼‰ã€unit_nameï¼ˆè‹¥ä¼ å…¥éç©ºï¼‰ã€publish_timeï¼ˆä»…å½“æä¾›ä¸”éç©ºæ—¶è¦†ç›–ï¼‰ï¼Œupdate_time
            - è‹¥éœ€æ”¹ä¸ºæŒ‰ URL åŒ¹é…ï¼Œå¯æ–°å¢å¯¹åº”æ–¹æ³•ã€‚
        """
        if not article_title:
            return False
        if not self.is_connected():
            if not self.reconnect():
                return False
        try:
            current_time = datetime.now()

            # å¤„ç†å‘å¸ƒæ—¶é—´
            publish_time = article_data.get('pub_time') or article_data.get('publish_time')
            if isinstance(publish_time, str) and publish_time:
                try:
                    publish_time_dt = datetime.strptime(publish_time, '%Y-%m-%d %H:%M:%S')
                except ValueError:
                    publish_time_dt = None
            elif isinstance(publish_time, datetime):
                publish_time_dt = publish_time
            else:
                publish_time_dt = None

            # è®¡ç®— analysis å­—æ®µçš„å€¼
            # å½“é˜…è¯»é‡ä¸º0ä¸”å…¶ä½™ç‚¹èµé‡æˆ–è€…å–œæ¬¢é‡æœ‰ä¸€ä¸ªä¸ä¸º0æ—¶è®¾ä¸º-1ï¼Œå…¶ä»–æ—¶å€™å‡è®¾ä¸º0
            view_count = article_data.get('view_count') or 0
            likes = article_data.get('like_count') or 0
            thumbs_count = article_data.get('old_like_count') or 0
            
            # è½¬æ¢ä¸ºæ•°å­—è¿›è¡Œæ¯”è¾ƒ
            try:
                view_count = int(view_count) if view_count else 0
                likes = int(likes) if likes else 0
                thumbs_count = int(str(thumbs_count).replace(',', '')) if thumbs_count else 0
            except (ValueError, TypeError):
                view_count = 0
                likes = 0
                thumbs_count = 0
            
            # åˆ¤æ–­åˆ†æå€¼ï¼šå½“é˜…è¯»é‡ä¸º0ä¸”ç‚¹èµé‡æˆ–å–œæ¬¢é‡æœ‰ä¸€ä¸ªä¸ä¸º0æ—¶è®¾ä¸º-1ï¼Œå¦åˆ™è®¾ä¸º0
            if view_count == 0 and (likes > 0 or thumbs_count > 0):
                analysis_value = -1
            else:
                analysis_value = 0

            sql = f"""
            UPDATE {self.table_name}
            SET
                article_content = %(article_content)s,
                view_count = %(view_count)s,
                likes = %(likes)s,
                share_count = %(share_count)s,
                thumbs_count = %(thumbs_count)s,
                comments = %(comments)s,
                article_url = CASE WHEN %(article_url)s IS NOT NULL AND %(article_url)s <> '' THEN %(article_url)s ELSE article_url END,
                unit_name = CASE WHEN %(unit_name)s IS NOT NULL AND %(unit_name)s <> '' THEN %(unit_name)s ELSE unit_name END,
                publish_time = CASE WHEN %(publish_time)s IS NOT NULL THEN %(publish_time)s ELSE publish_time END,
                update_time = %(update_time)s,
                analysis = %(analysis)s
            WHERE article_title = %(article_title)s
            """

            # è§£æ unit_nameï¼šæ›´æ–°æ—¶è‹¥æœªæ˜¾å¼æä¾› unit_name ä¸”ç»™äº† gzh_nameï¼Œåˆ™å°è¯•è§£æï¼›è§£æä¸åˆ°åˆ™ä¸è¦†ç›–åŸå€¼
            upd_unit_name = (article_data.get('unit_name') or '').strip()
            if (not upd_unit_name) and article_data.get('gzh_name'):
                resolved = self.resolve_unit_name(article_data.get('gzh_name'))
                if resolved:
                    upd_unit_name = resolved
                else:
                    # ç½®ç©ºè®© SQL CASE ä¸è¦†ç›–
                    upd_unit_name = ''

            params = {
                'article_content': article_data.get('content', ''),
                'view_count': article_data.get('view_count'),
                'likes': article_data.get('like_count'),
                'share_count': article_data.get('share_count'),
                'thumbs_count': article_data.get('old_like_count'),
                'comments': article_data.get('comment_count'),
                'article_url': article_data.get('url', ''),
                'unit_name': upd_unit_name,
                'publish_time': publish_time_dt,
                'update_time': current_time,
                'article_title': article_title,
                'analysis': analysis_value
            }

            with self.connection.cursor() as cursor:
                affected = cursor.execute(sql, params)
            if affected:
                self.logger.info(f"ğŸ”„ å·²æ›´æ–°æ–‡ç« ç»Ÿè®¡: {article_title}")
                return True
            else:
                self.logger.warning(f"â„¹ï¸ æ›´æ–°æœªå½±å“è¡Œï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {article_title}")
                return False
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°æ–‡ç« ç»Ÿè®¡å¤±è´¥: {e}")
            return False

    def upsert_article(self, article_data: Dict[str, Any]) -> str:
        """æ’å…¥æˆ–æ›´æ–°æ–‡ç« ã€‚

        è¿”å›å€¼:
            'inserted'  - æ–°æ’å…¥
            'updated'   - å·²å­˜åœ¨å¹¶æ›´æ–°
            'failed'    - å¤±è´¥
        """
        title = (article_data.get('title') or '').strip()
        if not title:
            return 'failed'
        try:
            if self.check_article_title_exists(title):
                ok = self.update_article_stats(title, article_data)
                return 'updated' if ok else 'failed'
            else:
                ok = self.insert_article(article_data)
                return 'inserted' if ok else 'failed'
        except Exception as e:
            self.logger.error(f"âŒ upsert å¤±è´¥: {e}")
            return 'failed'

    def check_article_title_exists(self, article_title: str) -> bool:
        """
        æ£€æŸ¥æ–‡ç« æ ‡é¢˜æ˜¯å¦å·²å­˜åœ¨ï¼ˆç”¨äºå»é‡ï¼‰

        Args:
            article_title: æ–‡ç« æ ‡é¢˜

        Returns:
            å­˜åœ¨è¿”å›Trueï¼Œä¸å­˜åœ¨è¿”å›False
        """
        if not self.is_connected():
            if not self.reconnect():
                return False

        try:
            sql = f"SELECT COUNT(*) as count FROM {self.table_name} WHERE article_title = %s"
            with self.connection.cursor() as cursor:
                cursor.execute(sql, (article_title,))
                result = cursor.fetchone()
                return result['count'] > 0
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥æ–‡ç« æ ‡é¢˜æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: {e}")
            return False
    
    def get_articles_count(self) -> int:
        """
        è·å–æ•°æ®åº“ä¸­æ–‡ç« æ€»æ•°
        
        Returns:
            æ–‡ç« æ€»æ•°
        """
        if not self.is_connected():
            if not self.reconnect():
                return 0
        
        try:
            sql = f"SELECT COUNT(*) as count FROM {self.table_name}"
            with self.connection.cursor() as cursor:
                cursor.execute(sql)
                result = cursor.fetchone()
                return result['count']
        except Exception as e:
            self.logger.error(f"è·å–æ–‡ç« æ€»æ•°æ—¶å‡ºé”™: {e}")
            return 0
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.disconnect()

    def resolve_unit_name(self, gzh_name: str, contrast_table: str = 'fx_unit_gzh_contrast') -> Optional[str]:
        """
        æ ¹æ® gzh_name ä»å¯¹ç…§è¡¨è·å–å•ä½åç§° unit_nameã€‚

        Args:
            gzh_name: å…¬ä¼—å·åç§°
            contrast_table: å¯¹ç…§è¡¨è¡¨å

        Returns:
            åŒ¹é…åˆ°çš„å•ä½åç§°ï¼ŒæœªåŒ¹é…è¿”å› None
        """
        if not gzh_name:
            return None
        if not self.is_connected():
            if not self.reconnect():
                return None
        try:
            sql = f"SELECT unit_name FROM {contrast_table} WHERE gzh_name = %s LIMIT 1"
            with self.connection.cursor() as cursor:
                cursor.execute(sql, (gzh_name,))
                row = cursor.fetchone()
                return (row or {}).get('unit_name') if row else None
        except Exception as e:
            self.logger.warning(f"å¯¹ç…§è¡¨è§£æå•ä½åç§°å¤±è´¥: {e}")
            return None
